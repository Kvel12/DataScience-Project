{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar configuración\n",
    "with open('../config.yml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    config_fuente = config['fuente']\n",
    "    config_bodega = config['bodega']\n",
    "\n",
    "# Crear conexiones\n",
    "url_fuente = f\"postgresql://{config_fuente['user']}:{config_fuente['password']}@{config_fuente['host']}:{config_fuente['port']}/{config_fuente['dbname']}\"\n",
    "url_bodega = f\"postgresql://{config_bodega['user']}:{config_bodega['password']}@{config_bodega['host']}:{config_bodega['port']}/{config_bodega['dbname']}\"\n",
    "\n",
    "fuente_conn = create_engine(url_fuente)\n",
    "bodega_conn = create_engine(url_bodega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta SQL para obtener los servicios y sus estados\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    s.id as servicio_id,\n",
    "    s.cliente_id,\n",
    "    s.mensajero_id as mensajero_inicial_id,\n",
    "    es.estado_id,\n",
    "    es.fecha as fecha_estado,\n",
    "    es.hora as hora_estado\n",
    "FROM mensajeria_servicio s\n",
    "JOIN mensajeria_estadosservicio es ON s.id = es.servicio_id\n",
    "ORDER BY s.id, es.fecha, es.hora\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer datos y dimensiones\n",
    "df = pd.read_sql(query, fuente_conn)\n",
    "dim_fecha = pd.read_sql_table('dim_fecha', bodega_conn)\n",
    "dim_cliente = pd.read_sql_table('dim_cliente', bodega_conn)\n",
    "dim_mensajero = pd.read_sql_table('dim_mensajero', bodega_conn)\n",
    "dim_estado = pd.read_sql_table('dim_estado', bodega_conn)\n",
    "dim_hora = pd.read_sql_table('dim_hora', bodega_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total registros en tabla de servicios: 128402\n",
      "Servicios únicos: 28430\n",
      "\n",
      "Distribución de estados:\n",
      "estado_id\n",
      "1    29627\n",
      "2    30249\n",
      "3     5202\n",
      "4    27542\n",
      "5    27335\n",
      "6     8447\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificaciones iniciales\n",
    "print(\"\\nTotal registros en tabla de servicios:\", len(df))\n",
    "print(\"Servicios únicos:\", df['servicio_id'].nunique())\n",
    "print(\"\\nDistribución de estados:\")\n",
    "print(df['estado_id'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Servicios con estados múltiples:\n",
      "estado_id\n",
      "1    1064\n",
      "2    2228\n",
      "3    1086\n",
      "4     376\n",
      "5     286\n",
      "6     106\n",
      "Name: servicio_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Análisis de estados múltiples\n",
    "estados_multiples = df.groupby(['servicio_id', 'estado_id']).size().reset_index(name='count')\n",
    "estados_multiples = estados_multiples[estados_multiples['count'] > 1]\n",
    "print(\"\\nServicios con estados múltiples:\")\n",
    "print(estados_multiples.groupby('estado_id')['servicio_id'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar formato de hora\n",
    "def limpiar_hora(hora_str):\n",
    "    try:\n",
    "        if '.' in str(hora_str):\n",
    "            return str(hora_str).split('.')[0]\n",
    "        return str(hora_str)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['hora_estado'] = df['hora_estado'].apply(limpiar_hora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    16:22:18\n",
      "1    17:51:20\n",
      "2    12:02:48\n",
      "3    12:16:00\n",
      "4    17:07:55\n",
      "Name: hora_estado, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['hora_estado'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de dato fecha_estado: object\n",
      "Tipo de dato hora_estado: object\n",
      "\n",
      "Ejemplos de fecha_estado:\n",
      "0    2023-09-19\n",
      "1    2023-10-13\n",
      "2    2023-10-31\n",
      "3    2023-10-31\n",
      "4    2023-10-31\n",
      "Name: fecha_estado, dtype: object\n",
      "\n",
      "Ejemplos de hora_estado:\n",
      "0    16:22:18\n",
      "1    17:51:20\n",
      "2    12:02:48\n",
      "3    12:16:00\n",
      "4    17:07:55\n",
      "Name: hora_estado, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Tipo de dato fecha_estado:\", df['fecha_estado'].dtype)\n",
    "print(\"Tipo de dato hora_estado:\", df['hora_estado'].dtype)\n",
    "print(\"\\nEjemplos de fecha_estado:\")\n",
    "print(df['fecha_estado'].head())\n",
    "print(\"\\nEjemplos de hora_estado:\")\n",
    "print(df['hora_estado'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Registros únicos por servicio_id: 28430\n",
      "\n",
      "Ejemplo de servicios con múltiples estados:\n",
      "        servicio_id  cliente_id  mensajero_inicial_id  estado_id fecha_estado  \\\n",
      "110965        24681          11                  48.0          1   2024-08-05   \n",
      "110966        24681          11                  48.0          2   2024-08-05   \n",
      "110967        24681          11                  48.0          4   2024-08-05   \n",
      "110968        24681          11                  48.0          3   2024-08-05   \n",
      "110969        24681          11                  48.0          3   2024-08-05   \n",
      "110970        24681          11                  48.0          3   2024-08-05   \n",
      "110971        24681          11                  48.0          3   2024-08-05   \n",
      "110972        24681          11                  48.0          3   2024-08-05   \n",
      "110973        24681          11                  48.0          3   2024-08-05   \n",
      "110974        24681          11                  48.0          3   2024-08-05   \n",
      "110975        24681          11                  48.0          3   2024-08-05   \n",
      "110976        24681          11                  48.0          3   2024-08-05   \n",
      "110977        24681          11                  48.0          3   2024-08-05   \n",
      "110978        24681          11                  48.0          3   2024-08-05   \n",
      "110979        24681          11                  48.0          3   2024-08-05   \n",
      "110980        24681          11                  48.0          3   2024-08-05   \n",
      "110981        24681          11                  48.0          3   2024-08-05   \n",
      "110982        24681          11                  48.0          3   2024-08-05   \n",
      "110983        24681          11                  48.0          3   2024-08-05   \n",
      "110984        24681          11                  48.0          3   2024-08-05   \n",
      "110985        24681          11                  48.0          3   2024-08-05   \n",
      "110986        24681          11                  48.0          3   2024-08-05   \n",
      "110987        24681          11                  48.0          3   2024-08-05   \n",
      "110988        24681          11                  48.0          3   2024-08-05   \n",
      "110989        24681          11                  48.0          3   2024-08-05   \n",
      "110990        24681          11                  48.0          3   2024-08-05   \n",
      "110991        24681          11                  48.0          3   2024-08-05   \n",
      "110992        24681          11                  48.0          3   2024-08-05   \n",
      "110993        24681          11                  48.0          3   2024-08-05   \n",
      "110994        24681          11                  48.0          3   2024-08-05   \n",
      "110995        24681          11                  48.0          3   2024-08-05   \n",
      "110996        24681          11                  48.0          3   2024-08-05   \n",
      "110997        24681          11                  48.0          3   2024-08-05   \n",
      "110998        24681          11                  48.0          3   2024-08-05   \n",
      "110999        24681          11                  48.0          3   2024-08-05   \n",
      "111000        24681          11                  48.0          3   2024-08-05   \n",
      "111001        24681          11                  48.0          3   2024-08-05   \n",
      "111002        24681          11                  48.0          3   2024-08-05   \n",
      "111003        24681          11                  48.0          3   2024-08-05   \n",
      "111004        24681          11                  48.0          3   2024-08-05   \n",
      "111005        24681          11                  48.0          3   2024-08-05   \n",
      "111006        24681          11                  48.0          5   2024-08-05   \n",
      "\n",
      "       hora_estado  \n",
      "110965    10:55:48  \n",
      "110966    11:01:44  \n",
      "110967    11:26:20  \n",
      "110968    11:27:11  \n",
      "110969    11:27:13  \n",
      "110970    11:27:14  \n",
      "110971    11:27:16  \n",
      "110972    11:27:17  \n",
      "110973    11:27:19  \n",
      "110974    11:27:20  \n",
      "110975    11:27:22  \n",
      "110976    11:27:26  \n",
      "110977    11:27:28  \n",
      "110978    11:27:29  \n",
      "110979    11:27:31  \n",
      "110980    11:27:32  \n",
      "110981    11:27:34  \n",
      "110982    11:27:36  \n",
      "110983    11:27:38  \n",
      "110984    11:27:39  \n",
      "110985    11:27:40  \n",
      "110986    11:27:41  \n",
      "110987    11:27:41  \n",
      "110988    11:27:41  \n",
      "110989    11:27:42  \n",
      "110990    11:27:43  \n",
      "110991    11:27:43  \n",
      "110992    11:27:43  \n",
      "110993    11:27:44  \n",
      "110994    11:27:44  \n",
      "110995    11:27:45  \n",
      "110996    11:27:46  \n",
      "110997    11:27:47  \n",
      "110998    11:27:47  \n",
      "110999    11:27:48  \n",
      "111000    11:27:49  \n",
      "111001    11:27:49  \n",
      "111002    11:27:50  \n",
      "111003    11:27:51  \n",
      "111004    11:27:52  \n",
      "111005    11:27:52  \n",
      "111006    11:49:40  \n"
     ]
    }
   ],
   "source": [
    "# Antes del pivoteo\n",
    "print(\"\\nRegistros únicos por servicio_id:\", df['servicio_id'].nunique())\n",
    "print(\"\\nEjemplo de servicios con múltiples estados:\")\n",
    "servicio_ejemplo = df.groupby('servicio_id').size().sort_values(ascending=False).head(1).index[0]\n",
    "print(df[df['servicio_id'] == servicio_ejemplo].sort_values(['fecha_estado', 'hora_estado']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cada estado, tomar el registro más relevante\n",
    "df_estados = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero procesamos el estado 3 (novedades) para tener la información de novedades disponible\n",
    "estado_3 = df[df['estado_id'] == 3].groupby('servicio_id').agg({\n",
    "    'fecha_estado': list,\n",
    "    'hora_estado': list,\n",
    "    'cliente_id': 'first',\n",
    "    'mensajero_inicial_id': 'first'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear columna de novedades para todos los servicios\n",
    "todos_servicios = df['servicio_id'].unique()\n",
    "df_novedades = pd.DataFrame({'servicio_id': todos_servicios})\n",
    "df_novedades['tiene_novedad'] = df_novedades['servicio_id'].isin(estado_3['servicio_id'])\n",
    "df_novedades['cantidad_novedades'] = 0  # Inicializar en 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución inicial de novedades:\n",
      "cantidad_novedades\n",
      "0     25163\n",
      "1      2182\n",
      "2       715\n",
      "3       220\n",
      "4        64\n",
      "5        30\n",
      "6        17\n",
      "7         9\n",
      "8        11\n",
      "9         6\n",
      "10        4\n",
      "11        2\n",
      "12        1\n",
      "13        1\n",
      "14        1\n",
      "17        1\n",
      "24        1\n",
      "30        1\n",
      "38        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Actualizar cantidad de novedades para servicios que sí tienen\n",
    "servicios_con_novedades = estado_3.copy()\n",
    "servicios_con_novedades['cantidad_novedades'] = servicios_con_novedades['fecha_estado'].str.len()\n",
    "df_novedades.update(\n",
    "    servicios_con_novedades[['servicio_id', 'cantidad_novedades']].set_index('servicio_id')\n",
    ")\n",
    "\n",
    "print(\"\\nDistribución inicial de novedades:\")\n",
    "print(df_novedades['cantidad_novedades'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total servicios después de procesar estados: 28430\n",
      "\n",
      "Distribución final de novedades:\n",
      "cantidad_novedades\n",
      "0.0     25164\n",
      "1.0      2182\n",
      "2.0       715\n",
      "3.0       220\n",
      "4.0        63\n",
      "5.0        30\n",
      "6.0        17\n",
      "7.0         9\n",
      "8.0        11\n",
      "9.0         6\n",
      "10.0        4\n",
      "11.0        2\n",
      "12.0        1\n",
      "13.0        1\n",
      "14.0        1\n",
      "17.0        1\n",
      "24.0        1\n",
      "30.0        1\n",
      "38.0        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ahora procesamos todos los estados\n",
    "for estado in [1, 2, 3, 4, 5, 6]:\n",
    "    if estado == 3:\n",
    "        estado_data = estado_3.copy()\n",
    "        estado_data['fecha_primera_novedad'] = estado_data['fecha_estado'].apply(lambda x: x[0] if x else None)\n",
    "        estado_data['hora_primera_novedad'] = estado_data['hora_estado'].apply(lambda x: x[0] if x else None)\n",
    "        estado_data['fecha_ultima_novedad'] = estado_data['fecha_estado'].apply(lambda x: x[-1] if x else None)\n",
    "        estado_data['hora_ultima_novedad'] = estado_data['hora_estado'].apply(lambda x: x[-1] if x else None)\n",
    "    else:\n",
    "        estado_data = df[df['estado_id'] == estado].groupby('servicio_id').agg({\n",
    "            'fecha_estado': 'first',\n",
    "            'hora_estado': 'first',\n",
    "            'cliente_id': 'first',\n",
    "            'mensajero_inicial_id': 'first'\n",
    "        }).reset_index()\n",
    "    \n",
    "    # Renombrar columnas según el estado\n",
    "    nombre_estado = {\n",
    "        1: 'iniciado',\n",
    "        2: 'asignado',\n",
    "        3: 'novedad',\n",
    "        4: 'recogido',\n",
    "        5: 'entregado',\n",
    "        6: 'cerrado'\n",
    "    }[estado]\n",
    "    \n",
    "    if estado == 3:\n",
    "        columnas_rename = {\n",
    "            'fecha_primera_novedad': f'fecha_{nombre_estado}',\n",
    "            'hora_primera_novedad': f'hora_{nombre_estado}',\n",
    "            'fecha_ultima_novedad': f'fecha_ultima_{nombre_estado}',\n",
    "            'hora_ultima_novedad': f'hora_ultima_{nombre_estado}'\n",
    "        }\n",
    "    else:\n",
    "        columnas_rename = {\n",
    "            'fecha_estado': f'fecha_{nombre_estado}',\n",
    "            'hora_estado': f'hora_{nombre_estado}'\n",
    "        }\n",
    "    \n",
    "    estado_data = estado_data.rename(columns=columnas_rename)\n",
    "    \n",
    "    if len(df_estados) == 0:\n",
    "        df_estados = estado_data\n",
    "        # Agregar información de novedades desde el principio\n",
    "        df_estados = df_estados.merge(df_novedades[['servicio_id', 'cantidad_novedades']], \n",
    "                                    on='servicio_id', \n",
    "                                    how='left')\n",
    "    else:\n",
    "        df_estados = df_estados.merge(estado_data, \n",
    "                                    on=['servicio_id', 'cliente_id', 'mensajero_inicial_id'], \n",
    "                                    how='outer')\n",
    "\n",
    "print(\"\\nTotal servicios después de procesar estados:\", len(df_estados))\n",
    "print(\"\\nDistribución final de novedades:\")\n",
    "print(df_estados['cantidad_novedades'].fillna(0).value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificación de completitud por estado:\n",
      "Estado iniciado: 28429 registros (100.00%)\n",
      "Estado asignado: 27702 registros (97.44%)\n",
      "Estado novedad: 3273 registros (11.51%)\n",
      "Estado recogido: 27016 registros (95.03%)\n",
      "Estado entregado: 26952 registros (94.80%)\n",
      "Estado cerrado: 8290 registros (29.16%)\n"
     ]
    }
   ],
   "source": [
    "# Verificaciones Adicionales\n",
    "print(\"\\nVerificación de completitud por estado:\")\n",
    "for estado in ['iniciado', 'asignado', 'novedad', 'recogido', 'entregado', 'cerrado']:\n",
    "    total = len(df_estados[pd.notna(df_estados[f'fecha_{estado}'])])\n",
    "    print(f\"Estado {estado}: {total} registros ({(total/len(df_estados)*100):.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular tiempos\n",
    "def calcular_tiempo_entre_estados(fecha1, hora1, fecha2, hora2):\n",
    "    try:\n",
    "        if pd.isna(fecha1) or pd.isna(fecha2) or pd.isna(hora1) or pd.isna(hora2):\n",
    "            return \"00:00:00\"\n",
    "        \n",
    "        timestamp1 = pd.to_datetime(f\"{fecha1} {hora1}\")\n",
    "        timestamp2 = pd.to_datetime(f\"{fecha2} {hora2}\")\n",
    "        \n",
    "        if timestamp2 < timestamp1:  # Si las fechas están invertidas\n",
    "            timestamp1, timestamp2 = timestamp2, timestamp1\n",
    "            \n",
    "        segundos = (timestamp2 - timestamp1).total_seconds()\n",
    "        hours = int(segundos // 3600)\n",
    "        minutes = int((segundos % 3600) // 60)\n",
    "        seconds = int(segundos % 60)\n",
    "        return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "    except:\n",
    "        return \"00:00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular tiempos entre estados\n",
    "df_estados['tiempo_asignacion'] = df_estados.apply(\n",
    "    lambda row: calcular_tiempo_entre_estados(\n",
    "        row['fecha_iniciado'], \n",
    "        row['hora_iniciado'],\n",
    "        row['fecha_asignado'],\n",
    "        row['hora_asignado']\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "# Para novedades, calcular tiempo total en novedades\n",
    "df_estados['tiempo_total_novedades'] = df_estados.apply(\n",
    "    lambda row: calcular_tiempo_entre_estados(\n",
    "        row['fecha_novedad'],\n",
    "        row['hora_novedad'],\n",
    "        row['fecha_ultima_novedad'],\n",
    "        row['hora_ultima_novedad']\n",
    "    ) if 'tiene_novedad' in row and row['tiene_novedad'] else \"00:00:00\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_estados['tiempo_recogida'] = df_estados.apply(\n",
    "    lambda row: calcular_tiempo_entre_estados(\n",
    "        row['fecha_asignado'], \n",
    "        row['hora_asignado'],\n",
    "        row['fecha_recogido'],\n",
    "        row['hora_recogido']\n",
    "    ) if not row.get('tiene_novedad', False) else\n",
    "    calcular_tiempo_entre_estados(\n",
    "        row['fecha_ultima_novedad'],\n",
    "        row['hora_ultima_novedad'],\n",
    "        row['fecha_recogido'],\n",
    "        row['hora_recogido']\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "df_estados['tiempo_entrega'] = df_estados.apply(\n",
    "    lambda row: calcular_tiempo_entre_estados(\n",
    "        row['fecha_recogido'], \n",
    "        row['hora_recogido'],\n",
    "        row['fecha_entregado'],\n",
    "        row['hora_entregado']\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "df_estados['tiempo_cierre'] = df_estados.apply(\n",
    "    lambda row: calcular_tiempo_entre_estados(\n",
    "        row['fecha_entregado'], \n",
    "        row['hora_entregado'],\n",
    "        row['fecha_cerrado'],\n",
    "        row['hora_cerrado']\n",
    "    ), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ejemplo de tiempos calculados para un servicio:\n",
      "Servicio ID: 7\n",
      "tiempo_asignacion: 577:29:02\n",
      "tiempo_total_novedades: 00:00:00\n",
      "tiempo_recogida: 426:11:28\n",
      "tiempo_entrega: 05:05:07\n",
      "tiempo_cierre: 04:51:55\n"
     ]
    }
   ],
   "source": [
    "# Verificar cálculo de tiempos\n",
    "print(\"\\nEjemplo de tiempos calculados para un servicio:\")\n",
    "servicio_ejemplo = df_estados.iloc[0]\n",
    "print(f\"Servicio ID: {servicio_ejemplo['servicio_id']}\")\n",
    "for tiempo in ['tiempo_asignacion', 'tiempo_total_novedades', 'tiempo_recogida', 'tiempo_entrega', 'tiempo_cierre']:\n",
    "    print(f\"{tiempo}: {servicio_ejemplo[tiempo]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir fechas al mismo formato\n",
    "df_estados['fecha_iniciado'] = pd.to_datetime(df_estados['fecha_iniciado']).dt.date\n",
    "dim_fecha['fecha'] = pd.to_datetime(dim_fecha['fecha']).dt.date\n",
    "\n",
    "# Obtener hora del día para dim_hora\n",
    "df_estados['hora_del_dia'] = df_estados['hora_iniciado'].apply(\n",
    "    lambda x: int(x.split(':')[0]) if pd.notna(x) else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros después de merge con dim_fecha: 28430\n"
     ]
    }
   ],
   "source": [
    "# Realizar los merges con las dimensiones\n",
    "hecho_acumulado = df_estados.merge(\n",
    "    dim_fecha[['key_dim_fecha', 'fecha']], \n",
    "    left_on='fecha_iniciado', \n",
    "    right_on='fecha',\n",
    "    how='left'\n",
    ")\n",
    "print(f\"Registros después de merge con dim_fecha: {len(hecho_acumulado)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros después de merge con dim_cliente: 28430\n"
     ]
    }
   ],
   "source": [
    "hecho_acumulado = hecho_acumulado.merge(\n",
    "    dim_cliente[['key_dim_cliente', 'cliente_id']], \n",
    "    on='cliente_id',\n",
    "    how='left'\n",
    ")\n",
    "print(f\"Registros después de merge con dim_cliente: {len(hecho_acumulado)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros después de merge con dim_mensajero: 28430\n"
     ]
    }
   ],
   "source": [
    "hecho_acumulado = hecho_acumulado.merge(\n",
    "    dim_mensajero[['key_dim_mensajero', 'mensajero_id']], \n",
    "    left_on='mensajero_inicial_id',\n",
    "    right_on='mensajero_id',\n",
    "    how='left'\n",
    ")\n",
    "print(f\"Registros después de merge con dim_mensajero: {len(hecho_acumulado)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros después de merge con dim_hora: 28430\n"
     ]
    }
   ],
   "source": [
    "hecho_acumulado = hecho_acumulado.merge(\n",
    "    dim_hora[['key_dim_hora', 'hora']], \n",
    "    left_on='hora_del_dia',\n",
    "    right_on='hora',\n",
    "    how='left'\n",
    ")\n",
    "print(f\"Registros después de merge con dim_hora: {len(hecho_acumulado)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar NaN en cantidad_novedades por 0\n",
    "hecho_acumulado['cantidad_novedades'] = hecho_acumulado['cantidad_novedades'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas finales\n",
    "columnas_finales = [\n",
    "    'servicio_id',\n",
    "    'key_dim_fecha',\n",
    "    'key_dim_cliente',\n",
    "    'key_dim_mensajero',\n",
    "    'key_dim_hora',\n",
    "    'fecha_iniciado',\n",
    "    'hora_iniciado',\n",
    "    'fecha_asignado',\n",
    "    'hora_asignado',\n",
    "    'fecha_novedad',\n",
    "    'hora_novedad',\n",
    "    'fecha_ultima_novedad',\n",
    "    'hora_ultima_novedad',\n",
    "    'fecha_recogido',\n",
    "    'hora_recogido',\n",
    "    'fecha_entregado',\n",
    "    'hora_entregado',\n",
    "    'fecha_cerrado',\n",
    "    'hora_cerrado',\n",
    "    'tiempo_asignacion',\n",
    "    'tiempo_total_novedades',\n",
    "    'tiempo_recogida',\n",
    "    'tiempo_entrega',\n",
    "    'tiempo_cierre',\n",
    "    'cantidad_novedades'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "hecho_acumulado = hecho_acumulado[columnas_finales]\n",
    "# Agregar fecha de carga\n",
    "hecho_acumulado['saved'] = date.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Información del DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28430 entries, 0 to 28429\n",
      "Data columns (total 26 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   servicio_id             28430 non-null  int64  \n",
      " 1   key_dim_fecha           28429 non-null  float64\n",
      " 2   key_dim_cliente         28430 non-null  int64  \n",
      " 3   key_dim_mensajero       27703 non-null  float64\n",
      " 4   key_dim_hora            28429 non-null  float64\n",
      " 5   fecha_iniciado          28429 non-null  object \n",
      " 6   hora_iniciado           28429 non-null  object \n",
      " 7   fecha_asignado          27702 non-null  object \n",
      " 8   hora_asignado           27702 non-null  object \n",
      " 9   fecha_novedad           3273 non-null   object \n",
      " 10  hora_novedad            3273 non-null   object \n",
      " 11  fecha_ultima_novedad    3273 non-null   object \n",
      " 12  hora_ultima_novedad     3273 non-null   object \n",
      " 13  fecha_recogido          27016 non-null  object \n",
      " 14  hora_recogido           27016 non-null  object \n",
      " 15  fecha_entregado         26952 non-null  object \n",
      " 16  hora_entregado          26952 non-null  object \n",
      " 17  fecha_cerrado           8290 non-null   object \n",
      " 18  hora_cerrado            8290 non-null   object \n",
      " 19  tiempo_asignacion       28430 non-null  object \n",
      " 20  tiempo_total_novedades  28430 non-null  object \n",
      " 21  tiempo_recogida         28430 non-null  object \n",
      " 22  tiempo_entrega          28430 non-null  object \n",
      " 23  tiempo_cierre           28430 non-null  object \n",
      " 24  cantidad_novedades      28430 non-null  float64\n",
      " 25  saved                   28430 non-null  object \n",
      "dtypes: float64(4), int64(2), object(20)\n",
      "memory usage: 5.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Verificaciones\n",
    "print(\"\\nInformación del DataFrame:\")\n",
    "print(hecho_acumulado.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total registros finales: 28430\n",
      "\n",
      "Distribución de novedades:\n",
      "cantidad_novedades\n",
      "0.0     25164\n",
      "1.0      2182\n",
      "2.0       715\n",
      "3.0       220\n",
      "4.0        63\n",
      "5.0        30\n",
      "6.0        17\n",
      "7.0         9\n",
      "8.0        11\n",
      "9.0         6\n",
      "10.0        4\n",
      "11.0        2\n",
      "12.0        1\n",
      "13.0        1\n",
      "14.0        1\n",
      "17.0        1\n",
      "24.0        1\n",
      "30.0        1\n",
      "38.0        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total registros finales: {len(hecho_acumulado)}\")\n",
    "print(\"\\nDistribución de novedades:\")\n",
    "print(hecho_acumulado['cantidad_novedades'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>servicio_id</th>\n",
       "      <th>key_dim_fecha</th>\n",
       "      <th>key_dim_cliente</th>\n",
       "      <th>key_dim_mensajero</th>\n",
       "      <th>key_dim_hora</th>\n",
       "      <th>fecha_iniciado</th>\n",
       "      <th>hora_iniciado</th>\n",
       "      <th>fecha_asignado</th>\n",
       "      <th>hora_asignado</th>\n",
       "      <th>fecha_novedad</th>\n",
       "      <th>...</th>\n",
       "      <th>hora_entregado</th>\n",
       "      <th>fecha_cerrado</th>\n",
       "      <th>hora_cerrado</th>\n",
       "      <th>tiempo_asignacion</th>\n",
       "      <th>tiempo_total_novedades</th>\n",
       "      <th>tiempo_recogida</th>\n",
       "      <th>tiempo_entrega</th>\n",
       "      <th>tiempo_cierre</th>\n",
       "      <th>cantidad_novedades</th>\n",
       "      <th>saved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>261.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2023-09-19</td>\n",
       "      <td>16:22:18</td>\n",
       "      <td>2023-10-13</td>\n",
       "      <td>17:51:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>17:07:55</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>12:16:00</td>\n",
       "      <td>577:29:02</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>426:11:28</td>\n",
       "      <td>05:05:07</td>\n",
       "      <td>04:51:55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>261.0</td>\n",
       "      <td>7</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2023-09-19</td>\n",
       "      <td>16:30:05</td>\n",
       "      <td>2023-12-20</td>\n",
       "      <td>20:14:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16:08:35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2211:44:38</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>1339:19:35</td>\n",
       "      <td>1320:34:17</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>261.0</td>\n",
       "      <td>7</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2023-09-19</td>\n",
       "      <td>16:30:05</td>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>19:33:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2403:02:56</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>261.0</td>\n",
       "      <td>7</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2023-09-19</td>\n",
       "      <td>16:35:52</td>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>19:33:07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>09:58:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2402:57:15</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>1228:48:40</td>\n",
       "      <td>513:36:40</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>261.0</td>\n",
       "      <td>7</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2023-09-19</td>\n",
       "      <td>16:37:54</td>\n",
       "      <td>2023-12-09</td>\n",
       "      <td>13:13:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1940:36:05</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>1269:15:56</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-11-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   servicio_id  key_dim_fecha  key_dim_cliente  key_dim_mensajero  \\\n",
       "0            7          261.0                7                0.0   \n",
       "1            8          261.0                7               13.0   \n",
       "2            9          261.0                7               13.0   \n",
       "3           10          261.0                7               13.0   \n",
       "4           11          261.0                7               13.0   \n",
       "\n",
       "   key_dim_hora fecha_iniciado hora_iniciado fecha_asignado hora_asignado  \\\n",
       "0          16.0     2023-09-19      16:22:18     2023-10-13      17:51:20   \n",
       "1          16.0     2023-09-19      16:30:05     2023-12-20      20:14:43   \n",
       "2          16.0     2023-09-19      16:30:05     2023-12-28      19:33:01   \n",
       "3          16.0     2023-09-19      16:35:52     2023-12-28      19:33:07   \n",
       "4          16.0     2023-09-19      16:37:54     2023-12-09      13:13:59   \n",
       "\n",
       "  fecha_novedad  ... hora_entregado fecha_cerrado hora_cerrado  \\\n",
       "0           NaN  ...       17:07:55    2023-10-31     12:16:00   \n",
       "1           NaN  ...       16:08:35           NaN          NaN   \n",
       "2           NaN  ...            NaN           NaN          NaN   \n",
       "3           NaN  ...       09:58:27           NaN          NaN   \n",
       "4           NaN  ...            NaN           NaN          NaN   \n",
       "\n",
       "  tiempo_asignacion tiempo_total_novedades tiempo_recogida tiempo_entrega  \\\n",
       "0         577:29:02               00:00:00       426:11:28       05:05:07   \n",
       "1        2211:44:38               00:00:00      1339:19:35     1320:34:17   \n",
       "2        2403:02:56               00:00:00        00:00:00       00:00:00   \n",
       "3        2402:57:15               00:00:00      1228:48:40      513:36:40   \n",
       "4        1940:36:05               00:00:00      1269:15:56       00:00:00   \n",
       "\n",
       "  tiempo_cierre cantidad_novedades       saved  \n",
       "0      04:51:55                0.0  2024-11-10  \n",
       "1      00:00:00                0.0  2024-11-10  \n",
       "2      00:00:00                0.0  2024-11-10  \n",
       "3      00:00:00                0.0  2024-11-10  \n",
       "4      00:00:00                0.0  2024-11-10  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hecho_acumulado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Registros con tiempos nulos:\n",
      "tiempo_asignacion: 0 registros nulos\n",
      "tiempo_recogida: 0 registros nulos\n",
      "tiempo_entrega: 0 registros nulos\n",
      "tiempo_cierre: 0 registros nulos\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRegistros con tiempos nulos:\")\n",
    "for tiempo in ['tiempo_asignacion', 'tiempo_recogida', 'tiempo_entrega', 'tiempo_cierre']:\n",
    "    nulos = hecho_acumulado[tiempo].isna().sum()\n",
    "    print(f\"{tiempo}: {nulos} registros nulos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificar completitud de estados:\n",
      "\n",
      "Estado iniciado:\n",
      "Registros sin fecha: 1\n",
      "Registros sin hora: 1\n",
      "\n",
      "Estado asignado:\n",
      "Registros sin fecha: 728\n",
      "Registros sin hora: 728\n",
      "\n",
      "Estado novedad:\n",
      "Registros sin fecha: 25157\n",
      "Registros sin hora: 25157\n",
      "\n",
      "Estado recogido:\n",
      "Registros sin fecha: 1414\n",
      "Registros sin hora: 1414\n",
      "\n",
      "Estado entregado:\n",
      "Registros sin fecha: 1478\n",
      "Registros sin hora: 1478\n",
      "\n",
      "Estado cerrado:\n",
      "Registros sin fecha: 20140\n",
      "Registros sin hora: 20140\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVerificar completitud de estados:\")\n",
    "for estado in ['iniciado', 'asignado', 'novedad', 'recogido', 'entregado', 'cerrado']:\n",
    "    fecha_nulos = hecho_acumulado[f'fecha_{estado}'].isna().sum()\n",
    "    hora_nulos = hecho_acumulado[f'hora_{estado}'].isna().sum()\n",
    "    print(f\"\\nEstado {estado}:\")\n",
    "    print(f\"Registros sin fecha: {fecha_nulos}\")\n",
    "    print(f\"Registros sin hora: {hora_nulos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificar registros con fechas fuera de secuencia:\n",
      "\n",
      "Servicio 7 tiene entregado después de cerrado\n",
      "entregado: 2023-10-31 17:07:55\n",
      "cerrado: 2023-10-31 12:16:00\n",
      "\n",
      "Servicio 22 tiene iniciado después de asignado\n",
      "iniciado: 2023-09-23 19:19:28\n",
      "asignado: 2023-09-22 19:45:37\n",
      "\n",
      "Servicio 23 tiene iniciado después de asignado\n",
      "iniciado: 2023-09-23 19:19:58\n",
      "asignado: 2023-09-22 19:45:37\n",
      "\n",
      "Servicio 24 tiene iniciado después de asignado\n",
      "iniciado: 2023-09-23 19:22:13\n",
      "asignado: 2023-09-22 19:45:37\n",
      "\n",
      "Servicio 25 tiene iniciado después de asignado\n",
      "iniciado: 2023-09-23 19:22:24\n",
      "asignado: 2023-09-22 19:45:30\n",
      "\n",
      "Servicio 26 tiene iniciado después de asignado\n",
      "iniciado: 2023-09-23 19:25:56\n",
      "asignado: 2023-09-22 19:45:20\n",
      "\n",
      "Servicio 83 tiene iniciado después de asignado\n",
      "iniciado: 2024-01-04 19:07:55\n",
      "asignado: 2024-01-03 22:20:44\n",
      "\n",
      "Servicio 86 tiene iniciado después de asignado\n",
      "iniciado: 2024-01-04 19:31:08\n",
      "asignado: 2024-01-03 19:31:51\n",
      "\n",
      "Servicio 87 tiene iniciado después de asignado\n",
      "iniciado: 2024-01-04 22:11:13\n",
      "asignado: 2024-01-03 22:20:10\n",
      "\n",
      "Servicio 95 tiene iniciado después de asignado\n",
      "iniciado: 2024-01-19 09:54:58\n",
      "asignado: 2024-01-18 19:32:55\n",
      "\n",
      "Servicio 23697 tiene asignado después de recogido\n",
      "asignado: 2024-07-29 14:38:42\n",
      "recogido: 2024-07-29 14:37:22\n",
      "\n",
      "Servicio 25645 tiene asignado después de recogido\n",
      "asignado: 2024-08-13 09:54:37\n",
      "recogido: 2024-08-13 09:54:01\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVerificar registros con fechas fuera de secuencia:\")\n",
    "for idx, row in hecho_acumulado.iterrows():\n",
    "    fechas = [\n",
    "        (pd.to_datetime(f\"{row['fecha_iniciado']} {row['hora_iniciado']}\") if pd.notna(row['fecha_iniciado']) else None, 'iniciado'),\n",
    "        (pd.to_datetime(f\"{row['fecha_asignado']} {row['hora_asignado']}\") if pd.notna(row['fecha_asignado']) else None, 'asignado'),\n",
    "        (pd.to_datetime(f\"{row['fecha_recogido']} {row['hora_recogido']}\") if pd.notna(row['fecha_recogido']) else None, 'recogido'),\n",
    "        (pd.to_datetime(f\"{row['fecha_entregado']} {row['hora_entregado']}\") if pd.notna(row['fecha_entregado']) else None, 'entregado'),\n",
    "        (pd.to_datetime(f\"{row['fecha_cerrado']} {row['hora_cerrado']}\") if pd.notna(row['fecha_cerrado']) else None, 'cerrado')\n",
    "    ]\n",
    "    fechas = [(f, e) for f, e in fechas if f is not None]\n",
    "    for i in range(len(fechas)-1):\n",
    "        if fechas[i][0] > fechas[i+1][0]:\n",
    "            print(f\"\\nServicio {row['servicio_id']} tiene {fechas[i][1]} después de {fechas[i+1][1]}\")\n",
    "            print(f\"{fechas[i][1]}: {row[f'fecha_{fechas[i][1]}']} {row[f'hora_{fechas[i][1]}']}\")\n",
    "            print(f\"{fechas[i+1][1]}: {row[f'fecha_{fechas[i+1][1]}']} {row[f'hora_{fechas[i+1][1]}']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estadísticas de tiempos:\n",
      "\n",
      "tiempo_asignacion:\n",
      "tiempo_asignacion\n",
      "00:00:00    729\n",
      "00:00:27     97\n",
      "00:00:20     87\n",
      "00:00:53     87\n",
      "00:00:26     85\n",
      "Name: count, dtype: int64\n",
      "\n",
      "tiempo_total_novedades:\n",
      "tiempo_total_novedades\n",
      "00:00:00    28430\n",
      "Name: count, dtype: int64\n",
      "\n",
      "tiempo_recogida:\n",
      "tiempo_recogida\n",
      "00:00:00    1414\n",
      "00:00:29      72\n",
      "00:00:33      71\n",
      "00:00:27      65\n",
      "00:00:38      63\n",
      "Name: count, dtype: int64\n",
      "\n",
      "tiempo_entrega:\n",
      "tiempo_entrega\n",
      "00:00:00    1479\n",
      "00:00:21      31\n",
      "00:00:30      31\n",
      "00:00:24      29\n",
      "00:00:35      29\n",
      "Name: count, dtype: int64\n",
      "\n",
      "tiempo_cierre:\n",
      "tiempo_cierre\n",
      "00:00:00    20141\n",
      "00:00:29       31\n",
      "00:00:25       30\n",
      "00:00:17       27\n",
      "00:00:23       27\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEstadísticas de tiempos:\")\n",
    "for tiempo in ['tiempo_asignacion', 'tiempo_total_novedades', \n",
    "               'tiempo_recogida', 'tiempo_entrega', 'tiempo_cierre']:\n",
    "    print(f\"\\n{tiempo}:\")\n",
    "    print(hecho_acumulado[tiempo].value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar en la bodega\n",
    "hecho_acumulado.to_sql('hecho_entrega_acumulado', bodega_conn, if_exists='replace', index_label='key_hecho_entrega_acumulado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSELECT \\n    m.mensajero_id,\\n    COUNT(*) AS total_servicios,\\n    AVG(CASE WHEN h.tiempo_asignacion = '00:00:00' THEN NULL \\n        ELSE EXTRACT(EPOCH FROM h.tiempo_asignacion::interval)/60 END) AS promedio_minutos_asignacion,\\n    AVG(CASE WHEN h.tiempo_recogida = '00:00:00' THEN NULL \\n        ELSE EXTRACT(EPOCH FROM h.tiempo_recogida::interval)/60 END) AS promedio_minutos_recogida,\\n    AVG(CASE WHEN h.tiempo_entrega = '00:00:00' THEN NULL \\n        ELSE EXTRACT(EPOCH FROM h.tiempo_entrega::interval)/60 END) AS promedio_minutos_entrega,\\n    AVG(CASE WHEN h.tiempo_cierre = '00:00:00' THEN NULL \\n        ELSE EXTRACT(EPOCH FROM h.tiempo_cierre::interval)/60 END) AS promedio_minutos_cierre,\\n    SUM(CASE WHEN h.cantidad_novedades > 0 THEN 1 ELSE 0 END) AS servicios_con_novedades,\\n    COUNT(*) FILTER (WHERE fecha_cerrado IS NOT NULL) AS servicios_completados,\\n    ROUND((COUNT(*) FILTER (WHERE fecha_cerrado IS NOT NULL)::NUMERIC / COUNT(*) * 100), 2) AS porcentaje_completados\\nFROM \\n    hecho_entrega_acumulado h\\n    JOIN dim_mensajero m ON h.key_dim_mensajero = m.key_dim_mensajero\\nGROUP BY \\n    m.mensajero_id\\nORDER BY \\n    total_servicios DESC;\\n\""
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pregunta 5: Mensajeros más eficientes (Los que más servicios prestan)\n",
    "\"\"\"\n",
    "SELECT \n",
    "    m.mensajero_id,\n",
    "    COUNT(*) AS total_servicios,\n",
    "    AVG(CASE WHEN h.tiempo_asignacion = '00:00:00' THEN NULL \n",
    "        ELSE EXTRACT(EPOCH FROM h.tiempo_asignacion::interval)/60 END) AS promedio_minutos_asignacion,\n",
    "    AVG(CASE WHEN h.tiempo_recogida = '00:00:00' THEN NULL \n",
    "        ELSE EXTRACT(EPOCH FROM h.tiempo_recogida::interval)/60 END) AS promedio_minutos_recogida,\n",
    "    AVG(CASE WHEN h.tiempo_entrega = '00:00:00' THEN NULL \n",
    "        ELSE EXTRACT(EPOCH FROM h.tiempo_entrega::interval)/60 END) AS promedio_minutos_entrega,\n",
    "    AVG(CASE WHEN h.tiempo_cierre = '00:00:00' THEN NULL \n",
    "        ELSE EXTRACT(EPOCH FROM h.tiempo_cierre::interval)/60 END) AS promedio_minutos_cierre,\n",
    "    SUM(CASE WHEN h.cantidad_novedades > 0 THEN 1 ELSE 0 END) AS servicios_con_novedades,\n",
    "    COUNT(*) FILTER (WHERE fecha_cerrado IS NOT NULL) AS servicios_completados,\n",
    "    ROUND((COUNT(*) FILTER (WHERE fecha_cerrado IS NOT NULL)::NUMERIC / COUNT(*) * 100), 2) AS porcentaje_completados\n",
    "FROM \n",
    "    hecho_entrega_acumulado h\n",
    "    JOIN dim_mensajero m ON h.key_dim_mensajero = m.key_dim_mensajero\n",
    "GROUP BY \n",
    "    m.mensajero_id\n",
    "ORDER BY \n",
    "    total_servicios DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWITH tiempos_totales AS (\\n    SELECT \\n        h.servicio_id,\\n        h.fecha_iniciado,\\n        h.hora_iniciado,\\n        h.fecha_cerrado,\\n        h.hora_cerrado,\\n        CASE \\n            WHEN h.fecha_cerrado IS NOT NULL THEN\\n                EXTRACT(EPOCH FROM (\\n                    (h.fecha_cerrado || ' ' || h.hora_cerrado)::timestamp - \\n                    (h.fecha_iniciado || ' ' || h.hora_iniciado)::timestamp\\n                ))/60.0\\n            ELSE NULL\\n        END AS minutos_totales\\n    FROM \\n        hecho_entrega_acumulado h\\n    WHERE \\n        h.fecha_cerrado IS NOT NULL\\n)\\nSELECT \\n    COUNT(*) AS total_servicios_completados,\\n    ROUND(AVG(minutos_totales), 2) AS promedio_minutos,\\n    ROUND(AVG(minutos_totales)/60, 2) AS promedio_horas,\\n    ROUND(AVG(minutos_totales)/1440, 2) AS promedio_dias,\\n    ROUND(MIN(minutos_totales)/60, 2) AS min_horas,\\n    ROUND(MAX(minutos_totales)/60, 2) AS max_horas\\nFROM \\n    tiempos_totales;\\n\""
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pregunta 7: Cuál es el tiempo promedio de entrega desde que se solicita el servicio hasta que se cierra el caso\n",
    "'''\n",
    "WITH tiempos_totales AS (\n",
    "    SELECT \n",
    "        h.servicio_id,\n",
    "        h.fecha_iniciado,\n",
    "        h.hora_iniciado,\n",
    "        h.fecha_cerrado,\n",
    "        h.hora_cerrado,\n",
    "        CASE \n",
    "            WHEN h.fecha_cerrado IS NOT NULL THEN\n",
    "                EXTRACT(EPOCH FROM (\n",
    "                    (h.fecha_cerrado || ' ' || h.hora_cerrado)::timestamp - \n",
    "                    (h.fecha_iniciado || ' ' || h.hora_iniciado)::timestamp\n",
    "                ))/60.0\n",
    "            ELSE NULL\n",
    "        END AS minutos_totales\n",
    "    FROM \n",
    "        hecho_entrega_acumulado h\n",
    "    WHERE \n",
    "        h.fecha_cerrado IS NOT NULL\n",
    ")\n",
    "SELECT \n",
    "    COUNT(*) AS total_servicios_completados,\n",
    "    ROUND(AVG(minutos_totales), 2) AS promedio_minutos,\n",
    "    ROUND(AVG(minutos_totales)/60, 2) AS promedio_horas,\n",
    "    ROUND(AVG(minutos_totales)/1440, 2) AS promedio_dias,\n",
    "    ROUND(MIN(minutos_totales)/60, 2) AS min_horas,\n",
    "    ROUND(MAX(minutos_totales)/60, 2) AS max_horas\n",
    "FROM \n",
    "    tiempos_totales;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWITH categorias_tiempo AS (\\n    SELECT \\n        servicio_id,\\n        cantidad_novedades,\\n        EXTRACT(EPOCH FROM tiempo_asignacion::interval)/3600 +\\n        EXTRACT(EPOCH FROM tiempo_recogida::interval)/3600 +\\n        EXTRACT(EPOCH FROM tiempo_entrega::interval)/3600 +\\n        EXTRACT(EPOCH FROM tiempo_cierre::interval)/3600 as horas_totales,\\n        CASE \\n            WHEN cantidad_novedades > 0 THEN 'Con Novedades'\\n            ELSE 'Sin Novedades'\\n        END as tipo_servicio\\n    FROM hecho_entrega_acumulado\\n    WHERE tiempo_asignacion != '00:00:00'\\n),\\nstats AS (\\n    SELECT \\n        tipo_servicio,\\n        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY horas_totales) + \\n        (PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY horas_totales) - \\n         PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY horas_totales)) * 1.5 as limite_superior\\n    FROM categorias_tiempo\\n    GROUP BY tipo_servicio\\n)\\nSELECT \\n    ct.tipo_servicio,\\n    COUNT(*) as total_servicios,\\n    CAST(AVG(ct.horas_totales) AS NUMERIC(10,2)) as promedio_horas,\\n    CAST(MIN(ct.horas_totales) AS NUMERIC(10,2)) as min_horas,\\n    CAST(MAX(ct.horas_totales) AS NUMERIC(10,2)) as max_horas,\\n    CAST(PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ct.horas_totales) AS NUMERIC(10,2)) as mediana\\nFROM categorias_tiempo ct\\nJOIN stats s ON ct.tipo_servicio = s.tipo_servicio\\nWHERE ct.horas_totales <= s.limite_superior  -- Eliminar outliers\\nGROUP BY ct.tipo_servicio\\nORDER BY ct.tipo_servicio;\\n\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pregunta 8: Mostrar los tiempos de espera por cada fase del servicio y en qué fase hay más demoras\n",
    "'''\n",
    "WITH tiempos_fase AS (\n",
    "    SELECT \n",
    "        'Asignación' as fase,\n",
    "        COUNT(*) FILTER (WHERE tiempo_asignacion != '00:00:00') as servicios_con_tiempo,\n",
    "        AVG(EXTRACT(EPOCH FROM tiempo_asignacion::interval)/60) as promedio_minutos,\n",
    "        MIN(EXTRACT(EPOCH FROM tiempo_asignacion::interval)/60) as min_minutos,\n",
    "        MAX(EXTRACT(EPOCH FROM tiempo_asignacion::interval)/60) as max_minutos,\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY EXTRACT(EPOCH FROM tiempo_asignacion::interval)/60) as mediana_minutos\n",
    "    FROM hecho_entrega_acumulado\n",
    "    WHERE tiempo_asignacion != '00:00:00'\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        'Recogida' as fase,\n",
    "        COUNT(*) FILTER (WHERE tiempo_recogida != '00:00:00') as servicios_con_tiempo,\n",
    "        AVG(EXTRACT(EPOCH FROM tiempo_recogida::interval)/60) as promedio_minutos,\n",
    "        MIN(EXTRACT(EPOCH FROM tiempo_recogida::interval)/60) as min_minutos,\n",
    "        MAX(EXTRACT(EPOCH FROM tiempo_recogida::interval)/60) as max_minutos,\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY EXTRACT(EPOCH FROM tiempo_recogida::interval)/60) as mediana_minutos\n",
    "    FROM hecho_entrega_acumulado\n",
    "    WHERE tiempo_recogida != '00:00:00'\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        'Entrega' as fase,\n",
    "        COUNT(*) FILTER (WHERE tiempo_entrega != '00:00:00') as servicios_con_tiempo,\n",
    "        AVG(EXTRACT(EPOCH FROM tiempo_entrega::interval)/60) as promedio_minutos,\n",
    "        MIN(EXTRACT(EPOCH FROM tiempo_entrega::interval)/60) as min_minutos,\n",
    "        MAX(EXTRACT(EPOCH FROM tiempo_entrega::interval)/60) as max_minutos,\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY EXTRACT(EPOCH FROM tiempo_entrega::interval)/60) as mediana_minutos\n",
    "    FROM hecho_entrega_acumulado\n",
    "    WHERE tiempo_entrega != '00:00:00'\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        'Cierre' as fase,\n",
    "        COUNT(*) FILTER (WHERE tiempo_cierre != '00:00:00') as servicios_con_tiempo,\n",
    "        AVG(EXTRACT(EPOCH FROM tiempo_cierre::interval)/60) as promedio_minutos,\n",
    "        MIN(EXTRACT(EPOCH FROM tiempo_cierre::interval)/60) as min_minutos,\n",
    "        MAX(EXTRACT(EPOCH FROM tiempo_cierre::interval)/60) as max_minutos,\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY EXTRACT(EPOCH FROM tiempo_cierre::interval)/60) as mediana_minutos\n",
    "    FROM hecho_entrega_acumulado\n",
    "    WHERE tiempo_cierre != '00:00:00'\n",
    ")\n",
    "SELECT \n",
    "    fase,\n",
    "    servicios_con_tiempo,\n",
    "    CAST(promedio_minutos AS NUMERIC(10,2)) as promedio_minutos,\n",
    "    CAST(promedio_minutos/60 AS NUMERIC(10,2)) as promedio_horas,\n",
    "    CAST(min_minutos AS NUMERIC(10,2)) as min_minutos,\n",
    "    CAST(max_minutos AS NUMERIC(10,2)) as max_minutos,\n",
    "    CAST(mediana_minutos AS NUMERIC(10,2)) as mediana_minutos\n",
    "FROM \n",
    "    tiempos_fase\n",
    "ORDER BY \n",
    "    promedio_minutos DESC;\n",
    "'''\n",
    "\n",
    "# Consulta SQL para ver comportamiento de las novedades sobre los otros estados\n",
    "'''\n",
    "WITH categorias_tiempo AS (\n",
    "    SELECT \n",
    "        servicio_id,\n",
    "        cantidad_novedades,\n",
    "        EXTRACT(EPOCH FROM tiempo_asignacion::interval)/3600 +\n",
    "        EXTRACT(EPOCH FROM tiempo_recogida::interval)/3600 +\n",
    "        EXTRACT(EPOCH FROM tiempo_entrega::interval)/3600 +\n",
    "        EXTRACT(EPOCH FROM tiempo_cierre::interval)/3600 as horas_totales,\n",
    "        CASE \n",
    "            WHEN cantidad_novedades > 0 THEN 'Con Novedades'\n",
    "            ELSE 'Sin Novedades'\n",
    "        END as tipo_servicio\n",
    "    FROM hecho_entrega_acumulado\n",
    "    WHERE tiempo_asignacion != '00:00:00'\n",
    "),\n",
    "stats AS (\n",
    "    SELECT \n",
    "        tipo_servicio,\n",
    "        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY horas_totales) + \n",
    "        (PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY horas_totales) - \n",
    "         PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY horas_totales)) * 1.5 as limite_superior\n",
    "    FROM categorias_tiempo\n",
    "    GROUP BY tipo_servicio\n",
    ")\n",
    "SELECT \n",
    "    ct.tipo_servicio,\n",
    "    COUNT(*) as total_servicios,\n",
    "    CAST(AVG(ct.horas_totales) AS NUMERIC(10,2)) as promedio_horas,\n",
    "    CAST(MIN(ct.horas_totales) AS NUMERIC(10,2)) as min_horas,\n",
    "    CAST(MAX(ct.horas_totales) AS NUMERIC(10,2)) as max_horas,\n",
    "    CAST(PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ct.horas_totales) AS NUMERIC(10,2)) as mediana\n",
    "FROM categorias_tiempo ct\n",
    "JOIN stats s ON ct.tipo_servicio = s.tipo_servicio\n",
    "WHERE ct.horas_totales <= s.limite_superior  -- Eliminar outliers\n",
    "GROUP BY ct.tipo_servicio\n",
    "ORDER BY ct.tipo_servicio;\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
